{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "import IPython\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector, Conv1D\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Osu_song_data_ABO.json') as f: #generated by osu_audio_bpm_extractor\n",
    "    Data = json.load(f)\n",
    "    print(len(Data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_song = list(Data.keys())[np.random.randint(len(Data.keys()))]\n",
    "audio, Bpm, Offset = Data[Random_song]\n",
    "Audio = Random_song + '/' + audio\n",
    "\n",
    "print(Random_song, audio, Bpm, Offset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y), sr, librosa.get_duration(y), len(y)/sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_spectrogram(data, rate):\n",
    "\n",
    "    nfft = 200 # Length of each window segment\n",
    "    fs = 8000 # Sampling frequencies\n",
    "    noverlap = 120 # Overlap between windows\n",
    "    nchannels = data.ndim\n",
    "    if nchannels == 1:\n",
    "        pxx, freqs, bins, im = plt.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "    elif nchannels == 2:\n",
    "        pxx, freqs, bins, im = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "    return pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librosa.reassigned_spectrogram(y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.specgram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_spectrogram(y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_section(start_ms, duration_s, data, sr):\n",
    "    \"\"\"start in ms, duration in sec, data (y), sr=rate\"\"\"\n",
    "    start_s = start_ms/1000.0\n",
    "    start = int(start_s * sr)\n",
    "    end_s = start_s + duration_s\n",
    "    end = int(end_s * sr)\n",
    "    if end > len(data):\n",
    "        return(data[start:])\n",
    "    else:\n",
    "        return(data[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = audio_section(Offset, 10.0, y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = graph_spectrogram(ys, sr)\n",
    "n_freq, Tx = x.shape\n",
    "print(n_freq, Tx)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write('temp_audio_section.wav', sr, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio('temp_audio_section.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(input_shape):\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    #1st layerS\n",
    "    X = Conv1D(filters=196, kernel_size=10, strides=2)(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    \n",
    "    #2nd layerS\n",
    "    X = GRU(units=128, return_sequences = True)(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = GRU(units=128, return_sequences = True)(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    #out\n",
    "    X = GRU(units=128, return_sequences = False)(X)\n",
    "    X = Dense(1, activation = \"relu\")(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(input_shape):\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    #1st layerS\n",
    "    X = Conv1D(filters=196, kernel_size=6, strides=2)(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('linear')(X)\n",
    "    X = Dropout(rate=0.6)(X)\n",
    "    \n",
    "    #2nd layerS\n",
    "    X = LSTM(128, return_sequences = True)(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = LSTM(128, return_sequences = False)(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(rate=0.8)(X)\n",
    "    \n",
    "    X = Dense(1)(X)\n",
    "    #X = Activation('linear')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelf(input_shape):\n",
    "    return(\n",
    "        model2(input_shape)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelf((Tx, n_freq))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_and_validation_samples(data, clip_duration_s, checkpoint = False):\n",
    "    X = []\n",
    "    Y = []\n",
    "    Songs = []\n",
    "    \n",
    "    _save_dir = \"D:/temp\"+\"/\"\n",
    "    \n",
    "    for i, song in enumerate(data.keys()):\n",
    "        audio, Bpm, Offset = data[song]\n",
    "        Audio = song + '/' + audio\n",
    "        y, sr = librosa.load(Audio)\n",
    "        ys = audio_section(Offset, clip_duration_s, y, sr)\n",
    "        x = graph_spectrogram(ys, sr)\n",
    "        if len(X)<=0:\n",
    "            X.append(x.swapaxes(0,1))\n",
    "            Y.append(Bpm)\n",
    "            Songs.append(song)\n",
    "            continue\n",
    "        \n",
    "        if x.swapaxes(0,1).shape==X[-1].shape:\n",
    "            X.append(x.swapaxes(0,1))\n",
    "            Y.append(Bpm)\n",
    "            Songs.append(song)\n",
    "        else:\n",
    "            print(i,Audio, x.shape)\n",
    "    \n",
    "        print(\"finished processing {}/{} songs\".format(i, len(data.keys())))\n",
    "        \n",
    "        if checkpoint and i%checkpoint == 0:\n",
    "            np.save(_save_dir + \"X_dataset_OsuBPM.npy\", np.asarray(X))\n",
    "            np.save(_save_dir + \"Y_dataset_OsuBPM.npy\", np.asarray(Y))\n",
    "            np.save(_save_dir + \"Songs_dataset_OsuBPM.npy\", np.asarray(Songs))\n",
    "        #    print(\"finished processing {} songs\".format(i))\n",
    "    return(np.array(X), np.array(Y), np.array(Songs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Osu_song_data_ABO.json') as f:\n",
    "    Data = json.load(f)\n",
    "X_dataset, Y_dataset, Songs_dataset = create_training_and_validation_samples(Data, 10.0, checkpoint=50)\n",
    "\n",
    "np.save(\"D:/temp\"+\"/\" + \"X_dataset_OsuBPM_Final.npy\", X_dataset)\n",
    "np.save(\"D:/temp\"+\"/\" + \"Y_dataset_OsuBPM_Final.npy\", Y_dataset)\n",
    "np.save(\"D:/temp\"+\"/\" + \"S_dataset_OsuBPM_Final.npy\", Songs_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"D:/temp\"+\"/\" + \"X_dataset_OsuBPM.npy\")\n",
    "Y = np.load(\"D:/temp\"+\"/\" + \"Y_dataset_OsuBPM.npy\")\n",
    "S = np.load(\"D:/temp\"+\"/\" + \"Songs_dataset_OsuBPM.npy\")\n",
    "print(X.shape, Y.shape, S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0], Y[0], S[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(0)\n",
    "#np.random.shuffle(X)\n",
    "\n",
    "shuffler = np.random.permutation(len(Y))\n",
    "X_shuff = X[shuffler,:,:]\n",
    "Y_shuff = Y[shuffler]\n",
    "S_shuff = S[shuffler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_shuff[0], Y_shuff[0], S_shuff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_data = len(Y)\n",
    "nb_train = int(nb_data*0.7)\n",
    "print(nb_data, nb_train)\n",
    "\n",
    "X_train = X_shuff[:nb_train, :,  :]\n",
    "Y_train = Y_shuff[:nb_train]\n",
    "\n",
    "X_test = X_shuff[nb_train:, : , :]\n",
    "Y_test = Y_shuff[nb_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=1e-2, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=3, validation_split=0.0, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weight_m4_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, = model.evaluate(X_test, Y_test)\n",
    "print(\"loss = \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('MSE')\n",
    "#plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Test\n",
    "\n",
    "file = r'path to a test file'\n",
    "y, sr = librosa.load(file)\n",
    "ys = audio_section(6592, 10.0, y, sr)\n",
    "x = graph_spectrogram(ys, sr)\n",
    "x = np.expand_dims(x.swapaxes(0,1), axis=0)\n",
    "\n",
    "#print(x.shape)\n",
    "#model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or alternatively\n",
    "path = r'path to a test file'\n",
    "a, b, o = Data[path]\n",
    "print(b, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write('temp_test.wav', sr, ys)\n",
    "IPython.display.Audio('temp_test.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test\n",
    "predictions = model.predict(x)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test on training samples\n",
    "n=0\n",
    "x = X_train[n]\n",
    "y = Y_train[n]\n",
    "\n",
    "print(x)\n",
    "print(np.amax(x), np.amin(x))\n",
    "\n",
    "pred = model.predict(np.array([x]))\n",
    "print(int(y), pred[0][0])\n",
    "print(\"error = {} bpm\".format(int(y) - int(pred[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print weights\n",
    "l = 3\n",
    "\n",
    "print(model.layers[l])\n",
    "print(model.layers[l].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
